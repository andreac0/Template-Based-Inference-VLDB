{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for template-based explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "from openai import OpenAI\n",
    "\n",
    "    # Paths of neuro-explain modules\n",
    "from main.verbalizer.utilsFunctions import *\n",
    "sys.path.append(os.path.abspath('main/preprocessor'))\n",
    "sys.path.append(os.path.abspath('main/verbalizer'))\n",
    "sys.path.append(os.path.abspath('main'))\n",
    "\n",
    "import FilePreprocessor\n",
    "import ChaseGraphVerbalizer\n",
    "import TemplatesGenerator\n",
    "import CorpusPreprocessor\n",
    "import AggregateVerbalizer\n",
    "import TemplatesGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_type = 'stress_test'\n",
    "csv_file_names = ['default']\n",
    "\n",
    "# Generic Path to folder\n",
    "path_g = \"Knowledge_Graph_Applications/\"\n",
    "\n",
    "# Path to the chase graph\n",
    "path_chase = os.path.join(path_g + program_type + '/chase_graph.json')\n",
    "# Path to the dependency graph\n",
    "path_plan = os.path.join(path_g + program_type+'/dependency_graph.json')\n",
    "# Add path to the predicates\n",
    "path_predicates = os.path.join('Domain_Glossary/' + program_type +'/predicates.json')\n",
    "# Add path to the a folder where results will be stored\n",
    "path_output = os.path.join(path_g + program_type+'/')\n",
    "# Path to the CSV files generated by Vadalog\n",
    "path_csv_output = path_g + program_type+'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deterministic Explanation via Chase Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, the chase graph is pre-processed, adding atoms that contributed to aggregations and by adding number to each step\n",
    "# importlib.reload(FilePreprocessor)\n",
    "FilePreprocessor.FilePreprocessor().integrate_previous_contributors_to_aggregations(path_chase,path_output)\n",
    "FilePreprocessor.FilePreprocessor().number_chase_graph(path_output+'aggr_chase_graph.json',path_output)\n",
    "path_num_chase = os.path.join(path_output, 'num_chase_graph.json')\n",
    "\n",
    "\n",
    "## Then, we can verbalize the entire chase graph, to obtain the deterministic explanations\n",
    "# importlib.reload(ChaseGraphVerbalizer)\n",
    "chasegraph_verbalizer = ChaseGraphVerbalizer.ChaseGraphVerbalizer()\n",
    "chasegraph_verbalizer.verbalize_chase_graph(path_num_chase, path_predicates, path_output)\n",
    "path_verb_chase = os.path.join(path_output, 'verb_chase_graph.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Template Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = TemplatesGenerator.TemplatesGenerator().get_program_paths(path_plan, path_output, path_predicates)\n",
    "templates_rec = TemplatesGenerator.TemplatesGenerator().get_recursive_template(templates,path_output, path_predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API Key\n",
    "\n",
    "client = OpenAI(api_key=\"YOURAPIKEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_templates = list()\n",
    "\n",
    "for i in range(len(templates[2])):\n",
    "    explanation = ' '.join(templates[2][i])\n",
    "    prompt = \"Rephrase the following text: \" + \"\\\"\" + explanation + \"\\\" \"\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            # model=\"gpt-4-1106-preview\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    },\n",
    "                ],\n",
    "            temperature=1,\n",
    "            max_tokens=1024,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "            )\n",
    "    paraphrased_templates.append(response.choices[0].message.content.strip()\\\n",
    "                                .replace('If','Since').replace('if','since')\\\n",
    "                                .replace('provided that','since')\\\n",
    "                                .replace('Assuming','Since').replace('assuming','since').replace('\\\"',''))\n",
    "templates_full = templates + (paraphrased_templates,)\n",
    "\n",
    "tt = list()\n",
    "for i in templates[2]:\n",
    "    tt.append(' '.join(i))\n",
    "\n",
    "df = pd.DataFrame(list(zip(tt, templates_full[3])), columns = ['Original Verbalization', 'Paraphrased Verbalization'])\n",
    "# Assuming the variable df contains the relevant DataFrame\n",
    "display(df.style.set_properties(**{'white-space': 'pre-wrap',}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the generated templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_output+'/templates.json', \"w\") as f:\n",
    "    json.dump(templates_full, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_output+'templates.json', 'r') as jsonfile:\n",
    "    templates_full = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load facts to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_to_explain = CorpusPreprocessor.CorpusPreprocessor().get_list_output_facts(csv_file_names, path_output, path_csv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chase_fact = list()\n",
    "for i in tqdm(range(len(facts_to_explain))):\n",
    "    chase_fact.append(AggregateVerbalizer.VerbalizationFinder().get_chase_fact(path_num_chase,facts_to_explain[i]))\n",
    "# chase_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the template-based explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(TemplatesGenerator)\n",
    "\n",
    "df = pd.DataFrame(columns=['DeterministicVerbalization','TemplateApproach'])\n",
    "\n",
    "for i in tqdm(range(len(facts_to_explain))):\n",
    "    try:\n",
    "        df = pd.concat([df,TemplatesGenerator.TemplatesGenerator().mapping_to_template(chase_fact[i][0], chase_fact[i][1], templates_full, templates_full, path_output, facts_to_explain[i], path_verb_chase)])\n",
    "    except:\n",
    "        print('Failed at mapping fact: ' + facts_to_explain[i])\n",
    "\n",
    "df = df.reset_index(drop = True)\n",
    "display(df.iloc[-10:].style.set_properties(**{'white-space': 'pre-wrap',}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "university",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
